experiment:
  data_config:
    strategy: fixed
    train_path: ../data/{0}/trainingset.tsv
    validation_path: ../data/{0}/validationset.tsv
    test_path: ../data/{0}/testset.tsv
    side_information:
      - dataloader: WordsTextualAttributes
        users_vocabulary_features: ../data/{0}/original/users_word2vec-google-news-300.npy
        items_vocabulary_features: ../data/{0}/original/items_word2vec-google-news-300.npy
        users_tokens: ../data/{0}/users_tokens_concat.json
        items_tokens: ../data/{0}/items_tokens_concat.json
  dataset: amazon_baby
  top_k: 50
  evaluation:
    cutoffs: [10, 20, 50]
    simple_metrics: [Recall, HR, nDCG, Precision, F1, MAP, MAR, LAUC, ItemCoverage, nDCGRendle2020, Gini, SEntropy, EFD, EPC]
  gpu: 0
  external_models_path: ../external/models/__init__.py
  models:
    external.DeepCoNN:
      meta:
        hyper_max_evals: 10
        hyper_opt_alg: tpe
        verbose: True
        save_recs: False
        save_weights: False
        validation_rate: 20
      epochs: 400
      lr: [loguniform, -11.512925465, -2.30258509299]
      latent_size: [5, 10, 20, 50, 100, 200, 500]
      l_w: [quniform, 10e-5, 10, 100]
      u_rev_cnn_kernel: (3,)
      i_rev_cnn_kernel: (3,)
      u_rev_cnn_features: (100,)
      i_rev_cnn_features: (100,)
      dropout: [loguniform, -2.30258509299, -0.69314718056]
      batch_size: 256
      batch_eval: 256
